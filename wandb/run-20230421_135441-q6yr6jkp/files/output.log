C:\Users\brian\miniconda3\envs\py38\lib\site-packages\torchvision\transforms\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
LOSS train 0.8167695999145508 valid 0.43632885813713074
LOSS train 0.8167695999145508 valid 0.6715894341468811
LOSS train 0.8167695999145508 valid 0.5979070067405701
LOSS train 0.8167695999145508 valid 0.5163955688476562
LOSS train 0.8167695999145508 valid 0.5413302183151245
LOSS train 0.8167695999145508 valid 0.5044533610343933
LOSS train 0.8167695999145508 valid 0.4963280260562897
LOSS train 0.8167695999145508 valid 0.5072246789932251
LOSS train 0.8167695999145508 valid 0.5052231550216675
LOSS train 0.8167695999145508 valid 0.5293496251106262
LOSS train 0.8167695999145508 valid 0.5111355185508728
LOSS train 0.8167695999145508 valid 0.5027754902839661
LOSS train 0.8167695999145508 valid 0.5097218155860901
LOSS train 0.8167695999145508 valid 0.5126567482948303
LOSS train 0.8167695999145508 valid 0.49446937441825867
LOSS train 0.8167695999145508 valid 0.49266868829727173
LOSS train 0.8167695999145508 valid 0.5003342032432556
LOSS train 0.8167695999145508 valid 0.5024397373199463
LOSS train 0.8167695999145508 valid 0.5042353272438049
LOSS train 0.8167695999145508 valid 0.49274080991744995
LOSS train 0.8167695999145508 valid 0.48475003242492676
LOSS train 0.8167695999145508 valid 0.47469156980514526
LOSS train 0.8167695999145508 valid 0.48524898290634155
LOSS train 0.8167695999145508 valid 0.4891684055328369
LOSS train 0.8167695999145508 valid 0.4905080497264862
LOSS train 0.8167695999145508 valid 0.5032438039779663
LOSS train 0.8167695999145508 valid 0.5008205771446228
LOSS train 0.8167695999145508 valid 0.4997246265411377
LOSS train 0.8167695999145508 valid 0.5075241327285767
LOSS train 0.8167695999145508 valid 0.5035814642906189
LOSS train 0.8167695999145508 valid 0.5125073194503784
LOSS train 0.8167695999145508 valid 0.5044777393341064
LOSS train 0.8167695999145508 valid 0.501754879951477
LOSS train 0.8167695999145508 valid 0.49817848205566406
LOSS train 0.8167695999145508 valid 0.49206307530403137
LOSS train 0.8167695999145508 valid 0.4854315221309662
LOSS train 0.8167695999145508 valid 0.47894182801246643
LOSS train 0.8167695999145508 valid 0.4817924499511719
LOSS train 0.8167695999145508 valid 0.4832335114479065
LOSS train 0.8167695999145508 valid 0.48219504952430725
LOSS train 0.8167695999145508 valid 0.48722198605537415
LOSS train 0.8167695999145508 valid 0.4809068441390991
LOSS train 0.8167695999145508 valid 0.4734019339084625
LOSS train 0.8167695999145508 valid 0.47063902020454407
LOSS train 0.8167695999145508 valid 0.47062021493911743
LOSS train 0.8167695999145508 valid 0.4642147421836853
LOSS train 0.8167695999145508 valid 0.4576863944530487
LOSS train 0.8167695999145508 valid 0.4642404019832611
LOSS train 0.8167695999145508 valid 0.4720408022403717
LOSS train 0.8167695999145508 valid 0.475177526473999
LOSS train 0.8167695999145508 valid 0.4733445346355438
LOSS train 0.8167695999145508 valid 0.46877482533454895
LOSS train 0.8167695999145508 valid 0.46760818362236023
LOSS train 0.8167695999145508 valid 0.46822330355644226
LOSS train 0.8167695999145508 valid 0.46808332204818726
LOSS train 0.8167695999145508 valid 0.46552029252052307
LOSS train 0.8167695999145508 valid 0.4626314342021942
LOSS train 0.8167695999145508 valid 0.46337372064590454
LOSS train 0.8167695999145508 valid 0.46552038192749023
LOSS train 0.8167695999145508 valid 0.4668385684490204
LOSS train 0.8167695999145508 valid 0.47098222374916077
LOSS train 0.8167695999145508 valid 0.47175708413124084
LOSS train 0.8167695999145508 valid 0.4695054292678833
LOSS train 0.8167695999145508 valid 0.4694814682006836
Traceback (most recent call last):
  File "c:/Users/brian/Documents/project-1-python-team_16/python/Brian/CNN/Training.py", line 193, in <module>
    model = stupid.runModel(train_load, test_load, device, "CNN")
  File "c:/Users/brian/Documents/project-1-python-team_16/python/Brian/CNN/Training.py", line 159, in runModel
    result = top_k_accuracy(outputs, labels, (1, 3, 5))
  File "c:/Users/brian/Documents/project-1-python-team_16/python/Brian/CNN/Training.py", line 56, in top_k_accuracy
    max_k_preds = np.argsort(scores, axis=1)[:, -k:][:, ::-1]
ValueError: step must be greater than zero
LOSS train 0.8167695999145508 valid 0.4702379107475281
LOSS train 0.8167695999145508 valid 0.47022369503974915
LOSS train 0.8167695999145508 valid 0.4664883017539978
LOSS train 0.8167695999145508 valid 0.46733391284942627
LOSS train 0.8167695999145508 valid 0.47220391035079956
LOSS train 0.8167695999145508 valid 0.4726469814777374
LOSS train 0.8167695999145508 valid 0.47144538164138794
LOSS train 0.8167695999145508 valid 0.47219011187553406
LOSS train 0.8167695999145508 valid 0.47138649225234985
LOSS train 0.8167695999145508 valid 0.47132131457328796
LOSS train 0.8167695999145508 valid 0.4718831777572632
LOSS train 0.8167695999145508 valid 0.4709106683731079
LOSS train 0.8167695999145508 valid 0.4666379988193512
LOSS train 0.8167695999145508 valid 0.46417418122291565
LOSS train 0.8167695999145508 valid 0.46427473425865173
LOSS train 0.8167695999145508 valid 0.4621371328830719
LOSS train 0.8167695999145508 valid 0.4584765136241913
LOSS train 0.8167695999145508 valid 0.4554978311061859
LOSS train 0.8167695999145508 valid 0.45557668805122375
LOSS train 0.8167695999145508 valid 0.4521155059337616
LOSS train 0.8167695999145508 valid 0.45437079668045044
LOSS train 0.8167695999145508 valid 0.45185786485671997
LOSS train 0.8167695999145508 valid 0.4549834728240967
LOSS train 0.8167695999145508 valid 0.4562325179576874
LOSS train 0.8167695999145508 valid 0.4561077058315277
LOSS train 0.8167695999145508 valid 0.4567583203315735
LOSS train 0.8167695999145508 valid 0.4573659896850586
LOSS train 0.8167695999145508 valid 0.46230340003967285
LOSS train 0.8167695999145508 valid 0.46248289942741394
LOSS train 0.8167695999145508 valid 0.46822091937065125
LOSS train 0.8167695999145508 valid 0.46769022941589355
LOSS train 0.8167695999145508 valid 0.4653165340423584
LOSS train 0.8167695999145508 valid 0.46528032422065735
LOSS train 0.8167695999145508 valid 0.46618929505348206
LOSS train 0.8167695999145508 valid 0.4642626941204071
LOSS train 0.8167695999145508 valid 0.46477532386779785
LOSS train 0.8167695999145508 valid 0.4656698703765869
LOSS train 0.8167695999145508 valid 0.4649754762649536
LOSS train 0.8167695999145508 valid 0.46450549364089966
LOSS train 0.8167695999145508 valid 0.46287280321121216
LOSS train 0.8167695999145508 valid 0.46295997500419617
LOSS train 0.8167695999145508 valid 0.4631010890007019
LOSS train 0.8167695999145508 valid 0.4647614657878876
LOSS train 0.8167695999145508 valid 0.4647192060947418
LOSS train 0.8167695999145508 valid 0.4648467004299164
LOSS train 0.8167695999145508 valid 0.46657872200012207
LOSS train 0.8167695999145508 valid 0.4667789936065674
LOSS train 0.8167695999145508 valid 0.46549081802368164
LOSS train 0.8167695999145508 valid 0.4634447395801544
LOSS train 0.8167695999145508 valid 0.4659307301044464
LOSS train 0.8167695999145508 valid 0.46320080757141113
LOSS train 0.8167695999145508 valid 0.46205127239227295
LOSS train 0.8167695999145508 valid 0.4598574638366699
LOSS train 0.8167695999145508 valid 0.4580537974834442
LOSS train 0.8167695999145508 valid 0.4591432809829712
LOSS train 0.8167695999145508 valid 0.45898452401161194
LOSS train 0.8167695999145508 valid 0.4607073664665222
LOSS train 0.8167695999145508 valid 0.4601610600948334
LOSS train 0.8167695999145508 valid 0.4619083106517792
LOSS train 0.8167695999145508 valid 0.4617452025413513
LOSS train 0.8167695999145508 valid 0.46384918689727783
LOSS train 0.8167695999145508 valid 0.46380099654197693
LOSS train 0.8167695999145508 valid 0.462764173746109
LOSS train 0.8167695999145508 valid 0.46226102113723755
LOSS train 0.8167695999145508 valid 0.46363967657089233
LOSS train 0.8167695999145508 valid 0.4640496075153351
LOSS train 0.8167695999145508 valid 0.4630076587200165
Loop Num: 1=========================================================