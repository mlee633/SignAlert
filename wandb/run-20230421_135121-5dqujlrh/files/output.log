C:\Users\brian\miniconda3\envs\py38\lib\site-packages\torchvision\transforms\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
LOSS train 0.7996319532394409 valid 0.23881511390209198
LOSS train 0.7996319532394409 valid 0.3019227087497711
LOSS train 0.7996319532394409 valid 0.3453633785247803
LOSS train 0.7996319532394409 valid 0.35247474908828735
LOSS train 0.7996319532394409 valid 0.35623663663864136
LOSS train 0.7996319532394409 valid 0.3473046123981476
LOSS train 0.7996319532394409 valid 0.32880231738090515
LOSS train 0.7996319532394409 valid 0.319086492061615
LOSS train 0.7996319532394409 valid 0.33346623182296753
LOSS train 0.7996319532394409 valid 0.32423362135887146
LOSS train 0.7996319532394409 valid 0.3478121757507324
LOSS train 0.7996319532394409 valid 0.36299803853034973
LOSS train 0.7996319532394409 valid 0.3665854036808014
LOSS train 0.7996319532394409 valid 0.37405362725257874
LOSS train 0.7996319532394409 valid 0.3849369287490845
LOSS train 0.7996319532394409 valid 0.38492199778556824
LOSS train 0.7996319532394409 valid 0.37892040610313416
LOSS train 0.7996319532394409 valid 0.3789982795715332
LOSS train 0.7996319532394409 valid 0.3706781566143036
LOSS train 0.7996319532394409 valid 0.37249404191970825
LOSS train 0.7996319532394409 valid 0.3824872374534607
LOSS train 0.7996319532394409 valid 0.3810102641582489
LOSS train 0.7996319532394409 valid 0.3835749924182892
LOSS train 0.7996319532394409 valid 0.37399789690971375
LOSS train 0.7996319532394409 valid 0.3717774450778961
LOSS train 0.7996319532394409 valid 0.37448832392692566
LOSS train 0.7996319532394409 valid 0.37086203694343567
LOSS train 0.7996319532394409 valid 0.3758088946342468
LOSS train 0.7996319532394409 valid 0.38230305910110474
LOSS train 0.7996319532394409 valid 0.38301393389701843
LOSS train 0.7996319532394409 valid 0.38904935121536255
LOSS train 0.7996319532394409 valid 0.39256128668785095
LOSS train 0.7996319532394409 valid 0.39441561698913574
LOSS train 0.7996319532394409 valid 0.3956693410873413
LOSS train 0.7996319532394409 valid 0.3978419005870819
LOSS train 0.7996319532394409 valid 0.4008331000804901
LOSS train 0.7996319532394409 valid 0.4008789360523224
LOSS train 0.7996319532394409 valid 0.40126606822013855
LOSS train 0.7996319532394409 valid 0.40511414408683777
LOSS train 0.7996319532394409 valid 0.40503159165382385
LOSS train 0.7996319532394409 valid 0.4021452069282532
LOSS train 0.7996319532394409 valid 0.39778703451156616
LOSS train 0.7996319532394409 valid 0.40163010358810425
LOSS train 0.7996319532394409 valid 0.4042416512966156
LOSS train 0.7996319532394409 valid 0.4018498361110687
LOSS train 0.7996319532394409 valid 0.40177515149116516
LOSS train 0.7996319532394409 valid 0.40319982171058655
LOSS train 0.7996319532394409 valid 0.40205785632133484
LOSS train 0.7996319532394409 valid 0.4018833339214325
LOSS train 0.7996319532394409 valid 0.4018877148628235
LOSS train 0.7996319532394409 valid 0.40387386083602905
LOSS train 0.7996319532394409 valid 0.40147069096565247
LOSS train 0.7996319532394409 valid 0.39830902218818665
LOSS train 0.7996319532394409 valid 0.3938797414302826
LOSS train 0.7996319532394409 valid 0.39314690232276917
LOSS train 0.7996319532394409 valid 0.39308640360832214
LOSS train 0.7996319532394409 valid 0.3897479474544525
LOSS train 0.7996319532394409 valid 0.38870471715927124
LOSS train 0.7996319532394409 valid 0.3846482038497925
LOSS train 0.7996319532394409 valid 0.38457903265953064
LOSS train 0.7996319532394409 valid 0.3826758861541748
LOSS train 0.7996319532394409 valid 0.3821404278278351
LOSS train 0.7996319532394409 valid 0.3856944143772125
LOSS train 0.7996319532394409 valid 0.38384580612182617
LOSS train 0.7996319532394409 valid 0.3865683972835541
LOSS train 0.7996319532394409 valid 0.38576436042785645
LOSS train 0.7996319532394409 valid 0.3854571282863617
LOSS train 0.7996319532394409 valid 0.38355353474617004
LOSS train 0.7996319532394409 valid 0.386433482170105
LOSS train 0.7996319532394409 valid 0.38643714785575867
LOSS train 0.7996319532394409 valid 0.3850291669368744
LOSS train 0.7996319532394409 valid 0.39040324091911316
LOSS train 0.7996319532394409 valid 0.3899627923965454
LOSS train 0.7996319532394409 valid 0.3914792239665985
LOSS train 0.7996319532394409 valid 0.38916781544685364
LOSS train 0.7996319532394409 valid 0.3895515501499176
LOSS train 0.7996319532394409 valid 0.3901609182357788
LOSS train 0.7996319532394409 valid 0.3890606760978699
LOSS train 0.7996319532394409 valid 0.3917069137096405
LOSS train 0.7996319532394409 valid 0.39300742745399475
LOSS train 0.7996319532394409 valid 0.39095115661621094
LOSS train 0.7996319532394409 valid 0.39012598991394043
LOSS train 0.7996319532394409 valid 0.3915124535560608
LOSS train 0.7996319532394409 valid 0.39167800545692444
LOSS train 0.7996319532394409 valid 0.3900495767593384
LOSS train 0.7996319532394409 valid 0.3873254656791687
LOSS train 0.7996319532394409 valid 0.3860318958759308
LOSS train 0.7996319532394409 valid 0.3841685950756073
LOSS train 0.7996319532394409 valid 0.3844612240791321
LOSS train 0.7996319532394409 valid 0.3843913972377777
LOSS train 0.7996319532394409 valid 0.38350987434387207
LOSS train 0.7996319532394409 valid 0.3809701204299927
LOSS train 0.7996319532394409 valid 0.3801352381706238
LOSS train 0.7996319532394409 valid 0.37880200147628784
LOSS train 0.7996319532394409 valid 0.37894728779792786
LOSS train 0.7996319532394409 valid 0.3765462338924408
LOSS train 0.7996319532394409 valid 0.37747877836227417
LOSS train 0.7996319532394409 valid 0.3753284513950348
LOSS train 0.7996319532394409 valid 0.3759106397628784
LOSS train 0.7996319532394409 valid 0.37524524331092834
LOSS train 0.7996319532394409 valid 0.3747600018978119
LOSS train 0.7996319532394409 valid 0.3742392659187317
LOSS train 0.7996319532394409 valid 0.37352558970451355
LOSS train 0.7996319532394409 valid 0.37636008858680725
LOSS train 0.7996319532394409 valid 0.37745627760887146
LOSS train 0.7996319532394409 valid 0.3784951865673065
LOSS train 0.7996319532394409 valid 0.37716561555862427
LOSS train 0.7996319532394409 valid 0.37680718302726746
LOSS train 0.7996319532394409 valid 0.3763224184513092
LOSS train 0.7996319532394409 valid 0.37678104639053345
LOSS train 0.7996319532394409 valid 0.3783014416694641
LOSS train 0.7996319532394409 valid 0.377063125371933
LOSS train 0.7996319532394409 valid 0.3752089738845825
LOSS train 0.7996319532394409 valid 0.3747885227203369
LOSS train 0.7996319532394409 valid 0.37573859095573425
LOSS train 0.7996319532394409 valid 0.37415117025375366
LOSS train 0.7996319532394409 valid 0.37585100531578064
LOSS train 0.7996319532394409 valid 0.3766886591911316
LOSS train 0.7996319532394409 valid 0.3753862679004669
LOSS train 0.7996319532394409 valid 0.37532320618629456
LOSS train 0.7996319532394409 valid 0.3748527765274048
LOSS train 0.7996319532394409 valid 0.3770389258861542
LOSS train 0.7996319532394409 valid 0.37624651193618774
LOSS train 0.7996319532394409 valid 0.37641456723213196
LOSS train 0.7996319532394409 valid 0.3756345510482788
LOSS train 0.7996319532394409 valid 0.3776003420352936
LOSS train 0.7996319532394409 valid 0.37796708941459656
LOSS train 0.7996319532394409 valid 0.3764210045337677
LOSS train 0.7996319532394409 valid 0.37563657760620117
LOSS train 0.7996319532394409 valid 0.3739621639251709
LOSS train 0.7996319532394409 valid 0.38058993220329285
Traceback (most recent call last):
  File "c:/Users/brian/Documents/project-1-python-team_16/python/Brian/CNN/Training.py", line 194, in <module>
    model = stupid.runModel(train_load, test_load, device, "CNN")
  File "c:/Users/brian/Documents/project-1-python-team_16/python/Brian/CNN/Training.py", line 152, in runModel
    result = top_k_accuracy(outputs, labels, )
  File "c:/Users/brian/Documents/project-1-python-team_16/python/Brian/CNN/Training.py", line 56, in top_k_accuracy
    max_k_preds = np.argsort(scores, axis=1)[:, -k:][:, ::-1]
ValueError: step must be greater than zero